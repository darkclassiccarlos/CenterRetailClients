# Listener Service

Servicio de procesamiento de eventos (Event Processor) para el sistema de inventario basado en arquitectura CQRS + EDA. Procesa eventos de Kafka y actualiza la base de datos SQLite (Single Writer Principle) con bloqueo optimista.

## üìã Descripci√≥n

Este servicio implementa el patr√≥n **Single Writer Principle** y **Optimistic Locking** para procesar eventos de Kafka y actualizar la base de datos SQLite (Inventory Database - Fuente de Verdad).

**Arquitectura Centralizada:** El inventario est√° centralizado en una base de datos SQLite que es la **√∫nica fuente autorizada** para realizar cambios en el stock. Las tiendas ya no escriben localmente y luego sincronizan; ahora deben llamar a la API central (Command Service) para reservar/descontar stock.

### Caracter√≠sticas Principales

- **Single Writer Principle**: Solo el Listener Service puede escribir en la base de datos transaccional
- **Optimistic Locking**: Usa version/timestamp para manejar concurrencia
- **Event Processing**: Consume eventos de Kafka y actualiza el Read Model
- **Retry Logic**: Reintentos autom√°ticos con backoff exponencial
- **Dead Letter Queue**: Manejo de eventos fallidos (placeholder)
- **Graceful Shutdown**: Cierre ordenado del servicio
- **REST API para Monitoreo**: Endpoints de monitoreo y estad√≠sticas (puerto 8082)

## üèóÔ∏è Arquitectura

Este servicio es el **√∫nico escritor** de la base de datos SQLite (Inventory Database), garantizando consistencia y evitando conflictos de escritura.

### Estructura del Proyecto

```
listener-service/
‚îú‚îÄ‚îÄ cmd/
‚îÇ   ‚îú‚îÄ‚îÄ listener/          # Punto de entrada del event processor
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ main.go
‚îÇ   ‚îî‚îÄ‚îÄ api/                # Punto de entrada del REST API (monitoreo)
‚îÇ       ‚îî‚îÄ‚îÄ main.go
‚îú‚îÄ‚îÄ internal/
‚îÇ   ‚îú‚îÄ‚îÄ config/             # Configuraci√≥n de la aplicaci√≥n
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ config.go
‚îÇ   ‚îú‚îÄ‚îÄ database/           # SQLite database (Single Writer)
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ sqlite.go
‚îÇ   ‚îú‚îÄ‚îÄ events/             # Event processor
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ event_processor.go
‚îÇ   ‚îú‚îÄ‚îÄ kafka/              # Kafka consumer
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ consumer.go
‚îÇ   ‚îî‚îÄ‚îÄ handlers/           # HTTP handlers para monitoreo
‚îÇ       ‚îú‚îÄ‚îÄ monitoring_handler.go
‚îÇ       ‚îî‚îÄ‚îÄ models.go
‚îú‚îÄ‚îÄ pkg/
‚îÇ   ‚îú‚îÄ‚îÄ logger/             # Utilidades de logging
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ logger.go
‚îÇ   ‚îú‚îÄ‚îÄ middleware/         # Middleware de Gin
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ error_handler.go
‚îÇ   ‚îî‚îÄ‚îÄ errors/             # Manejo de errores estandarizado
‚îÇ       ‚îî‚îÄ‚îÄ errors.go
‚îú‚îÄ‚îÄ docs/                    # Documentaci√≥n Swagger generada
‚îÇ   ‚îú‚îÄ‚îÄ docs.go
‚îÇ   ‚îú‚îÄ‚îÄ swagger.json
‚îÇ   ‚îî‚îÄ‚îÄ swagger.yaml
‚îú‚îÄ‚îÄ go.mod
‚îú‚îÄ‚îÄ go.sum
‚îú‚îÄ‚îÄ README.md                # Este archivo
‚îú‚îÄ‚îÄ SCHEMA.md                # Esquema de base de datos SQLite
‚îî‚îÄ‚îÄ TEST_RESULTS.md          # Resultados consolidados de pruebas
```

## üöÄ Inicio R√°pido

### Prerrequisitos

- **Go 1.20 o superior** - [Descargar Go](https://golang.org/dl/)
- **Kafka** - Para consumir eventos (opcional para desarrollo)
- **SQLite** - Incluido en Go (no requiere instalaci√≥n adicional)

### Instalaci√≥n y Ejecuci√≥n

#### 1. Navegar al Proyecto

```bash
cd listener-service
```

#### 2. Instalar Dependencias

```bash
go mod download
```

#### 3. Configurar Variables de Entorno (Opcional)

Crea un archivo `.env` en la ra√≠z del proyecto:

```env
ENVIRONMENT=development

# Kafka Configuration
KAFKA_BROKERS=localhost:9093
KAFKA_TOPIC_ITEMS=inventory.items
KAFKA_TOPIC_STOCK=inventory.stock
KAFKA_GROUP_ID=listener-service
KAFKA_AUTO_COMMIT=false

# SQLite Configuration
SQLITE_PATH=./inventory.db

# Retry Configuration
MAX_RETRIES=3
RETRY_DELAY_MS=1000

# Dead Letter Queue
DEAD_LETTER_QUEUE=true
DLQ_TOPIC=inventory.dlq

# REST API (Monitoreo)
API_PORT=8082
```

#### 4. Ejecutar el Event Processor

```bash
go run cmd/listener/main.go
```

El servicio se iniciar√° y comenzar√° a consumir eventos de Kafka.

#### 5. Ejecutar el REST API (Monitoreo) - Opcional

En otra terminal:

```bash
go run cmd/api/main.go
```

El API de monitoreo se iniciar√° en `http://localhost:8082`

#### 6. Verificar que el Servicio Est√° Corriendo

```bash
# Health check (REST API)
curl http://localhost:8082/api/v1/health

# Estad√≠sticas
curl http://localhost:8082/api/v1/monitoring/stats
```

## üì° Endpoints de Monitoreo

### Health Check
- `GET /api/v1/health` - Verifica el estado del servicio

### Monitoreo
- `GET /api/v1/monitoring/stats` - Estad√≠sticas de procesamiento de eventos
- `GET /api/v1/monitoring/health` - Health check detallado

### Swagger Documentation
- `GET /swagger/index.html` - Documentaci√≥n interactiva de la API (Swagger UI)

## ‚öôÔ∏è Configuraci√≥n

El servicio se configura mediante variables de entorno:

| Variable | Descripci√≥n | Default | Requerido |
|----------|-------------|---------|-----------|
| `ENVIRONMENT` | Ambiente de ejecuci√≥n (`development`/`production`) | `development` | No |
| `KAFKA_BROKERS` | Brokers de Kafka (comma-separated) | `localhost:9093` | No* |
| `KAFKA_TOPIC_ITEMS` | Topic para eventos de items | `inventory.items` | No |
| `KAFKA_TOPIC_STOCK` | Topic para eventos de stock | `inventory.stock` | No |
| `KAFKA_GROUP_ID` | Consumer group ID | `listener-service` | No |
| `KAFKA_AUTO_COMMIT` | Auto commit de offsets | `false` | No |
| `SQLITE_PATH` | Ruta al archivo SQLite | `./inventory.db` | No |
| `MAX_RETRIES` | M√°ximo n√∫mero de reintentos | `3` | No |
| `RETRY_DELAY_MS` | Delay entre reintentos (ms) | `1000` | No |
| `DEAD_LETTER_QUEUE` | Habilitar DLQ | `true` | No |
| `DLQ_TOPIC` | Topic para DLQ | `inventory.dlq` | No |
| `API_PORT` | Puerto del REST API (monitoreo) | `8082` | No |

\* *Requerido cuando se use Kafka real*

## üîí Single Writer Principle

Este servicio implementa el **Single Writer Principle** para garantizar que solo un proceso escriba en la base de datos SQLite:

- **Mutex**: Usa un mutex para serializar todas las escrituras
- **Connection Pool**: Configurado con `MaxOpenConns=1` para un solo escritor
- **Atomic Operations**: Todas las operaciones de escritura son at√≥micas

## üîÑ Optimistic Locking

El servicio usa **Optimistic Locking** con version/timestamp:

- **Version Field**: Cada registro tiene un campo `version` que se incrementa en cada actualizaci√≥n
- **Version Check**: Antes de actualizar, se verifica que la versi√≥n coincida
- **Conflict Detection**: Si la versi√≥n no coincide, se retorna `ErrOptimisticLockFailed`
- **Retry Logic**: Los conflictos se manejan con reintentos autom√°ticos

### Ejemplo de Optimistic Locking

```sql
UPDATE inventory_items
SET quantity = quantity + ?, version = version + 1, updated_at = ?
WHERE id = ? AND version = ? AND (quantity + ?) >= 0
```

Si la versi√≥n no coincide, la actualizaci√≥n falla y se reintenta.

## üîÑ Retry Logic

El servicio implementa retry logic con backoff exponencial:

- **Max Retries**: Configurable (default: 3)
- **Retry Delay**: Delay incremental entre reintentos
- **Optimistic Lock Failures**: Se reintentan autom√°ticamente
- **Other Errors**: Se reintentan seg√∫n configuraci√≥n

## üì® Dead Letter Queue

El servicio puede enviar eventos fallidos a un Dead Letter Queue:

- **DLQ Enabled**: Configurable (default: true)
- **DLQ Topic**: Configurable (default: `inventory.dlq`)
- **Failed Events**: Eventos que fallan despu√©s de todos los reintentos

**Nota:** Actualmente es un placeholder, pendiente de implementaci√≥n real.

## üìä Eventos Procesados

El servicio procesa los siguientes eventos:

### Items Events
- **InventoryItemCreated**: Crea un nuevo item
- **InventoryItemUpdated**: Actualiza un item existente
- **InventoryItemDeleted**: Elimina un item

### Stock Events
- **StockAdjusted**: Ajusta la cantidad de stock
- **StockReserved**: Reserva stock
- **StockReleased**: Libera stock reservado

## üéØ Flujo de Procesamiento

1. **Consume Event**: El consumer recibe un evento de Kafka
2. **Extract Event Type**: Extrae el tipo de evento de los headers
3. **Process Event**: Procesa el evento con retry logic
4. **Update Database**: Actualiza SQLite con optimistic locking
5. **Handle Failures**: Env√≠a a DLQ si falla despu√©s de reintentos
6. **Commit Offset**: Marca el mensaje como procesado

## üêõ Correcciones Implementadas

### Bug en `processStockAdjusted`

**Problema:** El m√©todo `processStockAdjusted` estaba calculando incorrectamente el ajuste de stock.

**C√≥digo Anterior (Incorrecto):**
```go
adjustment := event.Quantity - currentItem.Quantity
```

**Problema:** El evento `StockAdjustedEvent` que se publica desde Command Service tiene:
- `Quantity`: El ajuste (diferencia) que se quiere aplicar (ej: +25 o -30)
- `NewTotal`: La nueva cantidad total despu√©s del ajuste

El c√≥digo anterior estaba interpretando `event.Quantity` como la cantidad total nueva, cuando en realidad es el ajuste.

**C√≥digo Corregido:**
```go
// The event.Quantity field contains the adjustment (difference), not the new total
// For example: if stock was 100 and we adjust by +25, event.Quantity = 25
adjustment := event.Quantity
```

**Resultado:** Los valores de stock ahora se actualizan correctamente en todo el flujo.

## üóÑÔ∏è Esquema de Base de Datos

El servicio usa SQLite como base de datos √∫nica fuente de verdad. Ver `SCHEMA.md` para detalles completos del esquema.

### Tablas Principales

- **`stores`**: Informaci√≥n sobre las tiendas f√≠sicas
- **`inventory_items`**: Inventario centralizado (Single Source of Truth)
- **`store_reservations`**: Reservas de stock por tienda

## üß™ Pruebas

### Estado Actual

- ‚ö†Ô∏è **Pruebas Unitarias**: Pendientes de implementaci√≥n
- ‚ö†Ô∏è **Pruebas de Integraci√≥n**: Pendientes de implementaci√≥n
- ‚úÖ **Pruebas E2E**: Verificadas manualmente en flujo completo

Ver `TEST_RESULTS.md` para m√°s detalles sobre el estado de las pruebas.

## üìù Notas Importantes

### Estado Actual

- ‚úÖ **Implementado**: Single Writer Principle con mutex
- ‚úÖ **Implementado**: Optimistic Locking con version
- ‚úÖ **Implementado**: Event processing para todos los eventos
- ‚úÖ **Implementado**: Retry logic con backoff
- ‚úÖ **Implementado**: REST API para monitoreo
- ‚úÖ **Implementado**: Swagger documentation
- ‚ö†Ô∏è **Placeholder**: DLQ producer (pendiente implementaci√≥n real)
- ‚ö†Ô∏è **Pendiente**: Pruebas unitarias y de integraci√≥n

### Arquitectura Distribuida

Este servicio es parte de la arquitectura CQRS + EDA:

1. **Command Service** (puerto 8080) - Publica eventos a Kafka
2. **Query Service** (puerto 8081) - Lee desde Read Model/Cache
3. **Listener Service** (este servicio) - Procesa eventos y actualiza SQLite
4. **Kafka** - Event Broker
5. **SQLite** - Inventory Database (Fuente de Verdad)

### Pr√≥ximos Pasos de Implementaci√≥n

1. **DLQ Producer**: Implementar producer real para Dead Letter Queue
2. **Metrics**: Agregar m√©tricas de procesamiento
3. **Monitoring**: Agregar monitoreo y alertas
4. **Tests**: Unit tests e integration tests
5. **Documentaci√≥n**: Mejorar documentaci√≥n de eventos procesados

## üêõ Troubleshooting

### El servicio no inicia

- Verificar que Kafka est√© corriendo
- Verificar que los topics existan
- Verificar la configuraci√≥n de Kafka

### Errores de optimistic locking

- Normal en alta concurrencia
- El servicio reintenta autom√°ticamente
- Verificar logs para m√°s detalles

### Base de datos bloqueada

- Verificar que solo una instancia est√© corriendo
- Verificar permisos de escritura en SQLite
- Verificar que no haya otros procesos escribiendo

### Eventos no se procesan

- Verificar que Kafka est√© corriendo
- Verificar que los topics existan
- Verificar el consumer group ID
- Verificar los logs para errores

## üìö Recursos Adicionales

- **Esquema de Base de Datos**: Ver `SCHEMA.md` para detalles del esquema SQLite
- **Swagger UI**: `http://localhost:8082/swagger/index.html`
- **Pruebas**: Ver `TEST_RESULTS.md`
- **Command Service**: Ver `../command-service/README.md`
- **Query Service**: Ver `../query-service/README.md`
- **Arquitectura CQRS**: Ver documentaci√≥n de arquitectura distribuida
